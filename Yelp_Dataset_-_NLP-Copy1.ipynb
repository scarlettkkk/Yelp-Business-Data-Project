{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Challenge - NLP (Classification)\n",
    "\n",
    "BitTiger DS501\n",
    "\n",
    "Mar 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('last_2yr_restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Steakhouses, Restaurants, Cajun/Creole]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>0</td>\n",
       "      <td>nCqdz-NW64KazpxqnDr0sQ</td>\n",
       "      <td>1</td>\n",
       "      <td>I mainly went for the ceasar salad prepared ta...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>0XVzm4kVIAaH4eQAxWbhvw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Steakhouses, Restaurants, Cajun/Creole]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>0</td>\n",
       "      <td>iwx6s6yQxc7yjS7NFANZig</td>\n",
       "      <td>4</td>\n",
       "      <td>Nice atmosphere and wonderful service. I had t...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2aeNFntqY2QDZLADNo8iQQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Steakhouses, Restaurants, Cajun/Creole]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-05</td>\n",
       "      <td>0</td>\n",
       "      <td>2HrBENXZTiitcCJfzkELgA</td>\n",
       "      <td>2</td>\n",
       "      <td>To be honest it really quit aweful. First the ...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>WFhv5pMJRDPWSyLnKiWFXA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Steakhouses, Restaurants, Cajun/Creole]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>0</td>\n",
       "      <td>6YNPXoq41qTMZ2TEi0BYUA</td>\n",
       "      <td>2</td>\n",
       "      <td>The food was decent, but the service was defin...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2S6gWE-K3DHNcKYYSgN7xA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Steakhouses, Restaurants, Cajun/Creole]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-08</td>\n",
       "      <td>1</td>\n",
       "      <td>4bQrVUiRZ642odcKCS0OhQ</td>\n",
       "      <td>2</td>\n",
       "      <td>If you're looking for craptastic service and m...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>rCTVWx_Tws2jWi-K89iEyw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                  name  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "\n",
       "                                 categories  avg_stars  cool        date  \\\n",
       "0  [Steakhouses, Restaurants, Cajun/Creole]        4.0     0  2015-06-26   \n",
       "1  [Steakhouses, Restaurants, Cajun/Creole]        4.0     0  2015-06-29   \n",
       "2  [Steakhouses, Restaurants, Cajun/Creole]        4.0     0  2015-04-05   \n",
       "3  [Steakhouses, Restaurants, Cajun/Creole]        4.0     0  2016-02-16   \n",
       "4  [Steakhouses, Restaurants, Cajun/Creole]        4.0     0  2016-02-08   \n",
       "\n",
       "   funny               review_id  stars  \\\n",
       "0      0  nCqdz-NW64KazpxqnDr0sQ      1   \n",
       "1      0  iwx6s6yQxc7yjS7NFANZig      4   \n",
       "2      0  2HrBENXZTiitcCJfzkELgA      2   \n",
       "3      0  6YNPXoq41qTMZ2TEi0BYUA      2   \n",
       "4      1  4bQrVUiRZ642odcKCS0OhQ      2   \n",
       "\n",
       "                                                text    type  useful  \\\n",
       "0  I mainly went for the ceasar salad prepared ta...  review       0   \n",
       "1  Nice atmosphere and wonderful service. I had t...  review       0   \n",
       "2  To be honest it really quit aweful. First the ...  review       0   \n",
       "3  The food was decent, but the service was defin...  review       0   \n",
       "4  If you're looking for craptastic service and m...  review       1   \n",
       "\n",
       "                  user_id  count  \n",
       "0  0XVzm4kVIAaH4eQAxWbhvw      1  \n",
       "1  2aeNFntqY2QDZLADNo8iQQ      1  \n",
       "2  WFhv5pMJRDPWSyLnKiWFXA      1  \n",
       "3  2S6gWE-K3DHNcKYYSgN7xA      1  \n",
       "4  rCTVWx_Tws2jWi-K89iEyw      1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your feature variables, here is the text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents\"\n",
    "documents=df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'I mainly went for the ceasar salad prepared tableside.  I ate in the bar, the bartender was very nice and helpful.  I got the grilled cheese with tomato soup.  Grilled cheese was very good but the soup was nothing special.  Now the salad that i read one reviewer said the best in vegas, which is the only reason i came.  Knowing that they put anchovies in it when they prepare tableside, i was going to tell them to hold off on that once they get started.  So as im waiting for them to come up and make it, they bring it already prepared.  What is that?  The whole point of getting it is to watch it being done and see that its made fresh.  So obviously the anchovies were already in it, and since i explained i didnt want them, they made another.   I was told its a fire hazard to prepare it in the bar area so they made it on the side when i wasnt looking.  The few bites i took werent that good.  So i watch them make the 2nd salad in the hallway.  Needless to say, it was totally flavorless, ive had better dressing from newmans own, and the lettuce was in long stems, not even cut up. I was very disappointed with the salad, although the other food looked good',\n",
       "       \"Nice atmosphere and wonderful service. I had the dinner special which was a wedge salad, a petite ribeye, and desert.   \\n\\nThe salad was as expected. Nothing to jump up and down about. The petite ribeye was tasty. Just a minute over cooked, but overall it was good. The desert was ice cream and cake. As I'm not a cake eater I can't tell you about that, but the ice cream was good. \\n\\nOverall, it was a pleasant dinner.\",\n",
       "       \"To be honest it really quit aweful. First the host was uninviting. Sure not rude however I felt like I just walked into Denny's at 2:30 am for some pancakes. The wait staff was prompt however I would have rather been served by Denny's. They not nice and unattentive. They made us feel like it was best if we just hurried finished our meal. Of course we occommidated them becuase once started eating the food was certainly good quality but way over salted. It was very pasty. Odds are unless someone else insists I wont be visting again. Why when there are so many other great choices. One more thing. The restaurant really had no theme.  White walls coupled with the staff it felt like an expensive hospital cafeteria.\"], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect your documents, e.g. check the size, take a peek at elements of the numpy array\n",
    "documents[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your target variable (any categorical variable that may be meaningful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example, I am interested in perfect (5 stars) and imperfect (1-4 stars) rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a column and take the values, save to a variable named \"target\"\n",
    "df['perfectscore']=(df['stars']>4)\n",
    "df['perfectscore']=df['perfectscore'] * 1\n",
    "target=df['perfectscore'].values\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You may want to look at the statistic of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To be implemented\n",
    "target[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create training dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Documents is your X, target is your y\n",
    "# Now split the data to training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split to documents_train, documents_test, target_train, target_test\n",
    "documents_train, documents_test, target_train, target_test = train_test_split(documents, target, test_size=0.05, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get NLP representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330238,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_train.shape\n",
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=200, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=200)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the model with your training data\n",
    "train_vectors=vectorizer.fit_transform(documents_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330238, 200)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'10',\n",
       " u'20',\n",
       " u'actually',\n",
       " u'amazing',\n",
       " u'area',\n",
       " u'ask',\n",
       " u'asked',\n",
       " u'atmosphere',\n",
       " u'attentive',\n",
       " u'away',\n",
       " u'awesome',\n",
       " u'bacon',\n",
       " u'bad',\n",
       " u'bar',\n",
       " u'beef',\n",
       " u'best',\n",
       " u'better',\n",
       " u'big',\n",
       " u'bit',\n",
       " u'bread',\n",
       " u'breakfast',\n",
       " u'buffet',\n",
       " u'burger',\n",
       " u'busy',\n",
       " u'came',\n",
       " u'check',\n",
       " u'cheese',\n",
       " u'chicken',\n",
       " u'clean',\n",
       " u'coffee',\n",
       " u'come',\n",
       " u'coming',\n",
       " u'cooked',\n",
       " u'crab',\n",
       " u'cream',\n",
       " u'customer',\n",
       " u'day',\n",
       " u'decided',\n",
       " u'definitely',\n",
       " u'delicious',\n",
       " u'dessert',\n",
       " u'did',\n",
       " u'didn',\n",
       " u'different',\n",
       " u'dining',\n",
       " u'dinner',\n",
       " u'disappointed',\n",
       " u'dish',\n",
       " u'dishes',\n",
       " u'don',\n",
       " u'drink',\n",
       " u'drinks',\n",
       " u'eat',\n",
       " u'eating',\n",
       " u'enjoyed',\n",
       " u'excellent',\n",
       " u'experience',\n",
       " u'family',\n",
       " u'far',\n",
       " u'fast',\n",
       " u'favorite',\n",
       " u'feel',\n",
       " u'fish',\n",
       " u'flavor',\n",
       " u'food',\n",
       " u'free',\n",
       " u'fresh',\n",
       " u'fried',\n",
       " u'friend',\n",
       " u'friendly',\n",
       " u'friends',\n",
       " u'fries',\n",
       " u'gave',\n",
       " u'going',\n",
       " u'good',\n",
       " u'got',\n",
       " u'great',\n",
       " u'half',\n",
       " u'happy',\n",
       " u'high',\n",
       " u'highly',\n",
       " u'home',\n",
       " u'hot',\n",
       " u'hour',\n",
       " u'house',\n",
       " u'huge',\n",
       " u'husband',\n",
       " u'inside',\n",
       " u'items',\n",
       " u'just',\n",
       " u'kind',\n",
       " u'know',\n",
       " u'large',\n",
       " u'las',\n",
       " u'left',\n",
       " u'let',\n",
       " u'like',\n",
       " u'line',\n",
       " u'little',\n",
       " u'll',\n",
       " u'location',\n",
       " u'long',\n",
       " u'looking',\n",
       " u'lot',\n",
       " u'love',\n",
       " u'loved',\n",
       " u'lunch',\n",
       " u'make',\n",
       " u'manager',\n",
       " u'maybe',\n",
       " u'meal',\n",
       " u'meat',\n",
       " u'menu',\n",
       " u'minutes',\n",
       " u'need',\n",
       " u'new',\n",
       " u'nice',\n",
       " u'night',\n",
       " u'ok',\n",
       " u'open',\n",
       " u'order',\n",
       " u'ordered',\n",
       " u'overall',\n",
       " u'people',\n",
       " u'perfect',\n",
       " u'pizza',\n",
       " u'place',\n",
       " u'places',\n",
       " u'plate',\n",
       " u'pork',\n",
       " u'portions',\n",
       " u'pretty',\n",
       " u'price',\n",
       " u'prices',\n",
       " u'probably',\n",
       " u'quality',\n",
       " u'quick',\n",
       " u'really',\n",
       " u'recommend',\n",
       " u'restaurant',\n",
       " u'restaurants',\n",
       " u'rice',\n",
       " u'right',\n",
       " u'room',\n",
       " u'said',\n",
       " u'salad',\n",
       " u'sandwich',\n",
       " u'sauce',\n",
       " u'say',\n",
       " u'seated',\n",
       " u'served',\n",
       " u'server',\n",
       " u'service',\n",
       " u'shrimp',\n",
       " u'small',\n",
       " u'soup',\n",
       " u'special',\n",
       " u'spicy',\n",
       " u'spot',\n",
       " u'staff',\n",
       " u'star',\n",
       " u'stars',\n",
       " u'steak',\n",
       " u'strip',\n",
       " u'super',\n",
       " u'sure',\n",
       " u'sushi',\n",
       " u'sweet',\n",
       " u'table',\n",
       " u'tables',\n",
       " u'tacos',\n",
       " u'taste',\n",
       " u'tasted',\n",
       " u'tasty',\n",
       " u'tea',\n",
       " u'thai',\n",
       " u'thing',\n",
       " u'things',\n",
       " u'think',\n",
       " u'thought',\n",
       " u'time',\n",
       " u'times',\n",
       " u'told',\n",
       " u'took',\n",
       " u'town',\n",
       " u'tried',\n",
       " u'try',\n",
       " u've',\n",
       " u'vegas',\n",
       " u'visit',\n",
       " u'wait',\n",
       " u'waiter',\n",
       " u'waitress',\n",
       " u'want',\n",
       " u'wanted',\n",
       " u'wasn',\n",
       " u'water',\n",
       " u'way',\n",
       " u'went',\n",
       " u'worth']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocab of your tfidf\n",
    "vocab=vectorizer.get_feature_names()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the trained model to transform your test data\n",
    "y_test=target_test\n",
    "x_test=vectorizer.transform(documents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17381, 200)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar review search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We will need these helper methods pretty soon\n",
    "\n",
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"cat\", \"pig\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[::-1][:n]]  # np.argsort by default sorts values in ascending order\n",
    "                                                            #[::-1]is descending order\n",
    "\n",
    "def get_bottom_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the lowest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"mouse\", \"rabbit\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[:n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rabbit', 'mouse']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [7, 3, 2, 4, 1]\n",
    "n = 2\n",
    "labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "get_bottom_values(lst, n, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's use cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Draw an arbitrary review from test (unseen in training) documents\n",
    "arbreview=documents_test[42]\n",
    "queried_rev=[arbreview]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the drawn review(s) to vector(s)\n",
    "vector_rev=vectorizer.transform(queried_rev).toarray()\n",
    "vector_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the similarity score(s) between vector(s) and training vectors\n",
    "cossimilarity=cosine_similarity(vector_rev , train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.07793682,  0.        , ...,  0.07240568,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cossimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's find top 5 similar reviews\n",
    "n = 5\n",
    "lst=cossimilarity[0]\n",
    "labels=documents_train\n",
    "top_5=get_top_values(lst, n, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our search query:\n",
      "['Very tasty food! Atmosphere on the patio is amazing. Service was fantastic. Nothing we requested was forgotten. More bread, done! More wine, done! Food was delivered exactly as ordered. We were very impressed with our first visit to Salute. Have to give a shout out to our server, Kevin. Thanks for being so  good at your job! ;)']\n"
     ]
    }
   ],
   "source": [
    "print 'Our search query:'\n",
    "print  queried_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most 5 similar reviews:\n",
      "Top_1:\n",
      "The service was great and the food was definately above average but the two Kale salads that were ordered literally had no Kale in them so the server had to get 2 bowls of Kale to add. Lots of good beers on tap and a fun atmosphere.\n",
      "Top_2:\n",
      "Great food, atmosphere and service. \n",
      "\n",
      "Competitive pricing and food very tasty!\n",
      "Top_3:\n",
      "Good authentic Mexican food with a fun atmosphere. great service from our server Tillana too !\n",
      "Top_4:\n",
      "The service is supreme. And the food divine. The pumpkin bread is amazing and a delight.\n",
      "Top_5:\n",
      "Very tasty food. Owner is Italiano & she has a great sense of humor. The food was outstanding. My first visit and I was completely impressed. Mangia Mangia\n"
     ]
    }
   ],
   "source": [
    "print 'Most %s similar reviews:' % n\n",
    "for i, review in enumerate(top_5):\n",
    "    print \"Top_%s:\"%(i+1)\n",
    "    print review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Does the result make sense to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (insert your comments here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying positive/negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Naive-Bayes Classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model=MultinomialNB()\n",
    "model.fit(train_vectors,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75585486830709969"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model.score(train_vectors,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75835682641965363"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Logistic Regression Classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(train_vectors,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77437181668978128"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model.score(train_vectors,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77400609861342851"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What are the key features(words) that make the positive prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'20',\n",
       " u'attentive',\n",
       " u'ask',\n",
       " u'bread',\n",
       " u'favorite',\n",
       " u'different',\n",
       " u'clean',\n",
       " u'did',\n",
       " u'crab',\n",
       " u'eating',\n",
       " u'enjoyed',\n",
       " u'didn',\n",
       " u'bit',\n",
       " u'know',\n",
       " u'delicious',\n",
       " u'day',\n",
       " u'come',\n",
       " u'inside',\n",
       " u'happy',\n",
       " u'area']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find it out by ranking\n",
    "n = 20\n",
    "get_top_values(model.coef_[0][model.coef_[0]>0], n, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (insert your comments here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What are the key features(words) that make the negative prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'friendly',\n",
       " u'eating',\n",
       " u'friend',\n",
       " u'don',\n",
       " u'hour',\n",
       " u'friends',\n",
       " u'big',\n",
       " u'bit',\n",
       " u'decided',\n",
       " u'll',\n",
       " u'beef',\n",
       " u'didn',\n",
       " u'love',\n",
       " u'busy',\n",
       " u'family',\n",
       " u'fast',\n",
       " u'coming',\n",
       " u'enjoyed',\n",
       " u'highly',\n",
       " u'cream']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find it out by ranking\n",
    "n = 20\n",
    "get_top_values(model.coef_[0][model.coef_[0]<0], n, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (insert your comments here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier()\n",
    "model.fit(train_vectors,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98497750107498228"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model.score(train_vectors,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73948564524480753"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What do you see from the training score and the test score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (insert your comments here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00230931,  0.00165563,  0.00196741,  0.04325571,  0.0025802 ,\n",
       "        0.00196957,  0.00773813,  0.00389005,  0.00338643,  0.00217985,\n",
       "        0.01896679,  0.00192376,  0.00902757,  0.00374597,  0.00297405,\n",
       "        0.03675618,  0.0085297 ,  0.00298646,  0.00564775,  0.00258422,\n",
       "        0.00350173,  0.00301431,  0.00356806,  0.00257577,  0.00495175,\n",
       "        0.00210423,  0.00384645,  0.00600469,  0.0031197 ,  0.00228699,\n",
       "        0.00609589,  0.003561  ,  0.00267077,  0.0017848 ,  0.00204217,\n",
       "        0.00246356,  0.00327188,  0.00182417,  0.01213006,  0.02558394,\n",
       "        0.00272921,  0.00375353,  0.00988651,  0.00271709,  0.00192361,\n",
       "        0.00384839,  0.00266671,  0.00221089,  0.00253114,  0.00607826,\n",
       "        0.00252514,  0.00353612,  0.00528039,  0.00222228,  0.00302327,\n",
       "        0.01083605,  0.00460564,  0.00329241,  0.00209532,  0.0036564 ,\n",
       "        0.01066111,  0.00224618,  0.00217429,  0.00329014,  0.01621671,\n",
       "        0.00255354,  0.00728046,  0.00327906,  0.00202719,  0.01099141,\n",
       "        0.00260987,  0.00392735,  0.00165976,  0.00334012,  0.01868342,\n",
       "        0.00641072,  0.03744554,  0.00178103,  0.0038279 ,  0.00209724,\n",
       "        0.00873268,  0.00274979,  0.00337311,  0.00268574,  0.002299  ,\n",
       "        0.00300599,  0.00201524,  0.00224895,  0.00206377,  0.01212529,\n",
       "        0.00200051,  0.00289116,  0.00233945,  0.00311154,  0.00185735,\n",
       "        0.00193238,  0.00979069,  0.00213428,  0.00684814,  0.00317905,\n",
       "        0.00390638,  0.00329179,  0.00238895,  0.0028944 ,  0.01956344,\n",
       "        0.00660173,  0.00389775,  0.00406911,  0.00149623,  0.0038888 ,\n",
       "        0.00383866,  0.0031701 ,  0.00511018,  0.00675444,  0.00233308,\n",
       "        0.00371106,  0.00658175,  0.00392555,  0.0142999 ,  0.0023703 ,\n",
       "        0.00674925,  0.00809984,  0.00412825,  0.00417636,  0.00921037,\n",
       "        0.00394479,  0.01389763,  0.00276955,  0.00178093,  0.00250872,\n",
       "        0.00287118,  0.010133  ,  0.00449028,  0.00355563,  0.0026156 ,\n",
       "        0.0034805 ,  0.00315069,  0.00769413,  0.00585701,  0.0055793 ,\n",
       "        0.00206259,  0.00296099,  0.00415086,  0.00188029,  0.00516458,\n",
       "        0.0035075 ,  0.00227694,  0.00351096,  0.00367276,  0.00163588,\n",
       "        0.00201507,  0.00368318,  0.01277007,  0.00268649,  0.00363066,\n",
       "        0.00251274,  0.0025262 ,  0.00281862,  0.00420033,  0.00611232,\n",
       "        0.00322848,  0.00528355,  0.00319471,  0.00392807,  0.00478186,\n",
       "        0.00389779,  0.00355198,  0.00302017,  0.00338861,  0.00215258,\n",
       "        0.00259382,  0.00313482,  0.00255692,  0.00408118,  0.00201   ,\n",
       "        0.00198967,  0.00328555,  0.00184722,  0.00348927,  0.0018703 ,\n",
       "        0.00810563,  0.00322949,  0.00389419,  0.00407293,  0.0035266 ,\n",
       "        0.00348741,  0.0071026 ,  0.00610992,  0.01431972,  0.00300285,\n",
       "        0.00457061,  0.00193822,  0.00210263,  0.00310413,  0.00214261,\n",
       "        0.00744824,  0.0015814 ,  0.00365193,  0.00407279,  0.00490171])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Can you tell what features (words) are important by inspecting the RFC model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'amazing',\n",
       " u'great',\n",
       " u'best',\n",
       " u'delicious',\n",
       " u'love',\n",
       " u'awesome',\n",
       " u'good',\n",
       " u'food',\n",
       " u'vegas',\n",
       " u'ok',\n",
       " u'place',\n",
       " u'service',\n",
       " u'definitely',\n",
       " u'just',\n",
       " u'friendly',\n",
       " u'excellent',\n",
       " u'favorite',\n",
       " u'pretty',\n",
       " u'didn',\n",
       " u'like']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "get_top_values(model.feature_importances_, n, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit #1: Use cross validation to evaluate your classifiers\n",
    "\n",
    "[sklearn cross validation](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To be implemented\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit #2: Use grid search to find best predictable classifier\n",
    "\n",
    "\n",
    "[sklearn grid search tutorial (with cross validation)](http://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n",
    "\n",
    "[sklearn grid search documentation (with cross validation)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To be implemented\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
